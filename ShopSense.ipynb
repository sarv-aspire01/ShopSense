{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ShopSense\n",
    "#by sarvesh Pandey\n",
    "\n",
    "To get started, [get an API key](https://g.co/ai/idxGetGeminiKey) and replace the word `TODO` below with your API key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': '        To get started, get an GOOGLE_API_KEY and enter it in the first step    '}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['GOOGLE_API_KEY'] = 'Your_Api_Key_Here';\n",
    "\n",
    "if os.environ[\"GOOGLE_API_KEY\"] == 'YourApi_Key_Here':\n",
    "    print({ \"error\": '''\n",
    "        To get started, get an GOOGLE_API_KEY and enter it in the first step\n",
    "    '''.replace('\\n', '') })"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you're done, create a text prompt here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'Provide Details Of Britania Good Day Biscuits'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And load an image with PIL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "#img = PIL.Image.open('baked_goods_1.jpg')\n",
    "# img = PIL.Image.open('baked_goods_2.jpg')\n",
    "# img = PIL.Image.open('baked_goods_3.jpg')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, call the Gemini API using LangChain. [See the docs](https://github.com/langchain-ai/langchain/blob/master/libs/partners/google-genai/langchain_google_genai/__init__.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "     from langchain_core.messages import HumanMessage, SystemMessage\n",
    "     from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "     from IPython.display import Markdown, clear_output, display\n",
    "        #Current Ai Tunning \n",
    "     system_instruction = \"\"\"       \n",
    "     do a webscraping to get following \n",
    "    Provide Analysis\n",
    "    provide all information from genuine sources only, such as the product's own website, research papers, or government websites, brand website.\n",
    "    \n",
    "     Include ingredients, even hidden ones, if available (with pros and cons and effects on the human body).\n",
    "     provide exact name, effects,and source of exatra ingredients other then base (like emulsifier, preservative, and other chemicals and compositions & its bioavailability in nature) effect on body sâ€¦or RDA values), also must provide \"nutritional analysis\",  \"dietary intake\", \"health outcomes.\n",
    "     Mention health considerations like impact of the product on human body.\n",
    "     how this food is processed and what extra ingredients are used and there side effect on body(only if a genuine source is available).\n",
    "     provide naturally avallable alternative of the product with same ccost and better health impact and nutritions.\n",
    "     Provide the exact source of the above information (links preferred).\n",
    "\n",
    "     \"\"\"\n",
    "     model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")  # or gemini-1.5-pro\n",
    "     def chat(prompt):\n",
    "         messages = [\n",
    "             SystemMessage(content=system_instruction),\n",
    "             HumanMessage(content=prompt)\n",
    "         ]\n",
    "         buffer = []\n",
    "         for chunk in model.stream(messages, stop=None):\n",
    "             buffer.append(chunk.content)\n",
    "         clear_output()\n",
    "         display(Markdown(''.join(buffer)))\n",
    "     # Promp here:\n",
    "     chat(prompt)\n",
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "out",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
